defaults:
  - /network/base
  - _self_

name: SAC
unroll_length: 1
learning_rate: 3e-4
discount: 0.99
tau: 0.005
alpha: 0.2
batch_size: 64
grad_updates_per_step: 4
buffer_size: 100_000
learning_start: 100

network:
  policy:
    layer_sizes: [256, 256]
    activation: relu  # gelu, relu, selu
    final_activation: null

  value:
    layer_sizes: [256, 256]
    activation: relu  # gelu, relu, selu
    final_activation: relu  # tanh, relu
    num_networks: 2
    shared_encoder: false
